---
title: "Interactive Dashboard"
output: 
  flexdashboard::flex_dashboard:
    theme:
      version: 4
      bg: "#101010"
      fg: "#FDF7F7" 
      primary: "#ED79F9"
      navbar-bg: "#3ADAC6"
      base_font: 
    orientation: columns
    vertical_layout: fill
runtime: shiny
css: "Styles.css"  
---

```{r setup, include=FALSE}
pacman::p_load(tidyverse, ggplot2, gganimate, flexdashboard, mosaic, moderndive, effectsize, modelr, rsample, car,ggridges,plotly,broom,shiny)





consumption_date <- read.csv("~/Banana_project/consumption_date.csv")
consumption_traffic <-  read_csv("~/Banana_project/consumption_traffic.csv")
Consumption_Log <- read_csv("~/Banana_project/consumption_log.csv")
bananas_thrown_away <- read_csv("~/Banana_project/bananas_thrown_away.csv")
by_time <- consumption_traffic %>% 
  group_by(time_period) %>% 
  summarize(
    total_bananas = sum(bananas_consumed, na.rm = TRUE), 
    avg_bananas = mean(bananas_consumed, na.rm = TRUE)   
  )

by_time_long <- by_time %>% 
  pivot_longer(cols = c(total_bananas, avg_bananas), 
               names_to = "metric", 
               values_to = "value")




```

## Dashboard {.tabset}
---
title: "Banana Consumption Optimization Dashboard"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
---

### Banana Consumption Optimization

Welcome to the project dashboard for banana consumption optimization! This dashboard is designed to document the process, from data collection to insights, visualizations, and actionable outcomes.

---

#### Table of Contents:
- [Quick Summary](#summary)
- [Core Problem and Questions](#problem-statement)
- [Key Metrics and Visualizations](#key-metrics)
- [Database Schema and Design](#database-schema)

---

<a id="quick-summary"></a>
### Quick Summary: Why Bananas Matter
It all began with a simple question: *How many bananas should I take each day to ensure none are wasted while still meeting my nutritional needs?* Bananas, with their delicate ripeness curve and their tendency to rot when overstocked, seemed like the perfect candidate for such an optimization problem. But as I dug deeper, I realized that there were so many variables at play: day of the week, time of day, crowd levels, and even the ripeness itself.

My initial plan was to use SQL to track everything—I was learning it at the time—but I quickly pivoted to Google Sheets for simplicity. Over time, this project evolved into something far bigger: a full-fledged dashboard built with **Flexdashboard** and **Shiny** that ties together data, analysis, and machine learning.

Steps Taken:
1. Defined the core problem statement and identified key questions.
2. Designed a schema to organize my data.
3. Collected data over a month, wrangling it into a format suitable for analysis.
4. Performed statistical tests and built predictive models to optimize banana consumption.

---

<a id="problem-statement"></a>
### The Core Problem: Wastage vs. Need

At the heart of this project lies one burning question: **What is the optimal number of bananas to take each day to ensure no bananas are wasted while meeting daily consumption needs?**

#### Secondary Questions:
- How do factors like day of the week, crowd levels, restock schedules, and ripeness affect consumption patterns?
- How does ripeness influence the likelihood of a banana being consumed or thrown away?
- Are there specific times or days when consumption is most efficient?
- Can predictive models improve decisions about when to restock and how many bananas to take?

The journey started with a challenge: bananas are perishable. Too few, and I’d run out. Too many, and I’d throw them away. To strike a balance, I had to analyze historical consumption data, model patterns, and predict future needs.

---

<a id="key-metrics"></a>
### Key Metrics and Approach

#### Metrics Used:
1. **Ripeness**: Measured on a scale of 1 to 5, with 1 being underripe and 5 being fully ripe.
2. **Date**: Every entry was timestamped.
3. **Is_weekend**: A binary variable to capture weekend vs. weekday patterns.
4. **Consumption of bananas**: Total bananas consumed per time period.
5. **Time of day**: Morning, afternoon, evening, and late night.
6. **Crowd levels**: How busy the dining hall was during the time of consumption.

#### Analytical Approach:
1. **Daily Trends**: Visualized banana consumption patterns over weekdays and weekends. Significant differences were uncovered using statistical tests like t-tests.
   - Visualization: A line graph highlighted daily banana consumption trends, with weekend data plotted separately. T-tests confirmed a statistically significant difference between weekdays and weekends (*p < 0.001*).
   - *See [Daily Trends Tab](#tab-1) for the full analysis.*

2. **Time Period Analysis**: Conducted an ANOVA test to identify how time of day influenced consumption.
   - Visualization: A faceted bar chart showed total and average bananas consumed by time period. ANOVA revealed significant differences between late-night consumption and other time periods (*F = 12.34, p < 0.001*), with Tukey’s HSD pinpointing late-night as the outlier.
   - *See [Time Period Analysis Tab](#tab-2) for details.*

3. **Ripeness and Wastage**: Explored the relationship between ripeness and likelihood of wastage. Surprisingly, ripeness didn’t significantly predict consumption but heavily influenced wastage rates.
   - Visualization: Density plots illustrated the distribution of bananas consumed at different ripeness levels. A Kruskal-Wallis test (*p = 0.41*) confirmed no significant effect of ripeness on consumption, but a bar chart revealed higher wastage at ripeness levels 4 and 5.
   - *See [Ripeness and Wastage Tab](#tab-3) for insights.*

4. **Predictive Modeling**: Built and compared machine learning models (Gradient Boosting, Random Forest) to forecast future consumption. These models were fine-tuned for optimal performance.
   - Visualization: Bar charts compared RMSE values across models, with Gradient Boosting outperforming others (RMSE = 0.18).
   - *See [Machine Learning Tab](#tab-4) for results.*

---

<a id="findings"></a>
### Major Findings: Insights From the Data

#### Finding 1: Weekends Are Bananas
**Evidence:**
- Visualization: A line graph showed a clear spike in weekend consumption, nearly doubling weekday averages.
- Statistical Test: A t-test confirmed the difference, with a p-value < 0.001 and a 95% confidence interval of -8.15 to -6.18 bananas in favor of weekends.

#### Finding 2: Late-Night Cravings
**Evidence:**
- Visualization: A bar chart highlighted that late-night consumption far exceeded other periods.
- Statistical Test: ANOVA (*F = 12.34, p < 0.001*) and Tukey’s HSD identified late-night as significantly different from other time periods, likely due to dining hall closures.

#### Finding 3: Ripeness vs. Reality
**Evidence:**
- Visualization: Density plots showed similar consumption patterns across ripeness levels, but bar charts revealed increased wastage at ripeness levels 4 and 5.
- Statistical Test: A Kruskal-Wallis test (*p = 0.41*) indicated no significant effect of ripeness on consumption.

#### Finding 4: Predictive Models Work
**Evidence:**
- Visualization: A bar chart comparing RMSE values showed Gradient Boosting (RMSE = 0.18) and Random Forest (RMSE = 0.2) as the best-performing models.
- Statistical Evaluation: Cross-validation confirmed these models’ ability to accurately predict future consumption.

#### Finding 5: Crowd Levels Don’t Matter
**Evidence:**
- Visualization: Box plots showed no discernible pattern between crowd levels and banana consumption.
- Statistical Test: A Kruskal-Wallis test (*p = 0.086*) and pairwise comparisons revealed no statistically significant differences.

---

For detailed visualizations and statistical results, explore the corresponding tabs:
- **Daily Trends**: [See Tab 1](#tab-1)
- **Time Period Analysis**: [See Tab 2](#tab-2)
- **Ripeness and Wastage**: [See Tab 3](#tab-3)
- **Machine Learning Models**: [See Tab 4](#tab-4)

<a id="machine-learning"></a>
### Machine Learning Exploration

The journey into machine learning began as an exploration of various models, each with unique strengths and limitations. Here’s how I systematically narrowed down the most effective approach to predicting banana consumption:

#### Phase 1: Starting Simple with Linear Regression
I began with linear regression, treating it as a baseline machine learning model. Splitting the data into a **70/30 train-test split**, I calculated performance metrics such as:
- **Mean Absolute Error (MAE):** 0.21
- **Mean Squared Error (MSE):** 0.35

Visualization:
A scatterplot of predicted vs. actual values showed a general alignment but highlighted limitations in capturing variability, especially for extreme values.

#### Phase 2: Trying Multiple Models
I expanded to more complex models, including:
1. **Neural Network**
2. **Multi-Linear Regression**
3. **Random Forest**
4. **Gradient Boosting**
5. **AdaBoost**

To ensure a fair comparison, I standardized the dataset and applied **10-fold cross-validation** for evaluation. The primary metric for comparison was **Root Mean Squared Error (RMSE):**
- **Gradient Boosting:** 0.18 (Best performer)
- **Random Forest:** 0.20
- **Neural Network:** 0.44
- **Linear Regression:** 0.65

Visualization:
A bar chart compared RMSE values, highlighting Gradient Boosting and Random Forest as the top contenders.

#### Phase 3: Fine-Tuning with Hyperparameter Optimization
To improve performance, I fine-tuned the top models (Gradient Boosting and Random Forest) using a hyperparameter grid search. Parameters such as tree depth, learning rate, and number of estimators were optimized using the **caret** package.

Results:
- Gradient Boosting: RMSE improved slightly to **0.17**
- Random Forest: RMSE improved to **0.19**

Visualization:
A side-by-side bar chart displayed the pre- and post-tuning RMSE values for both models, showing only marginal improvements.

#### Phase 4: Predicting Future Consumption
Finally, I used the fine-tuned models to predict banana consumption for the following week. The predictions aligned closely with historical trends, as shown in a faceted scatterplot comparing predicted and actual values.

Key Observations:
- **Gradient Boosting** captured subtle consumption patterns better than Random Forest.
- **Random Forest** produced smoother predictions but struggled with sharp fluctuations.

Visualization:
The scatterplot of predictions vs. actuals illustrated the models’ accuracy, with Gradient Boosting consistently outperforming others in responsiveness and precision.

---

### Tab 1: Daily Trend



#### Chart A

```{r}

banana_plot <- ggplot(consumption_date, aes(x = as.Date(date_id), y = total_bananas)) +
  geom_line(color = "blue", size = 1) + 
  geom_point(color = "orange", size = 2, alpha = 0.6) +  
  facet_wrap(~is_weekend, labeller = as_labeller(c(`0` = "Non-Weekend", `1` = "Weekend"))) +
  scale_y_continuous(
    limits = c(0, 20),  
    breaks = seq(0, 20, by = 5)  
  ) +
  labs(title = "Daily Banana Consumption Over Time",
       x = "Date",
       y = "Total Bananas Consumed") +
  theme_dark() +
  theme(
    panel.grid.major = element_line(color = "lightgrey", size = 0.5),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(fill = "lightblue", color = "darkblue"),
    strip.text = element_text(color = "white", face = "bold"),
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.title.x = element_text(face = "bold", size = 12),
    axis.title.y = element_text(face = "bold", size = 12),
    axis.text.y = element_text(color = "white"),
     panel.background = element_rect(fill = "transparent", color = NA),  
    plot.background = element_rect(fill = "transparent", color = NA)   
  )

interactive_plot <- ggplotly(banana_plot)
interactive_plot


```

#### Chart B

```{r}
weeeknd_final <-  ggplot(consumption_date, aes(x = as.factor(is_weekend), y = total_bananas, fill = as.factor(is_weekend))) +
  geom_violin(trim = FALSE, alpha = 0.5) +
  geom_boxplot(width = 0.1) +
  labs(
    title = "Distribution of Banana Consumption: Weekdays vs. Weekends",
    x = "Is Weekend (0 = Weekday, 1 = Weekend)",
    y = "Total Bananas Consumed"
  ) +
  theme_minimal() +
  theme(
     legend.position = "none",
     panel.background = element_rect(fill = "transparent", color = NA),  
    plot.background = element_rect(fill = "transparent", color = NA),
    axis.title = element_text(color = "white"),
    axis.text = element_text(color = "#008080", size = 12)
  )

weekend_interactive <-  ggplotly(weeeknd_final)
renderPlotly({
  weekend_interactive
})

```
### Tab 2:Timed period

#### Chart A
```{r}
time_1 <- ggplot(by_time_long, aes(x = time_period, y = value, fill = metric)) +
  geom_col(position = "dodge") +
  facet_wrap(~metric, scales = "free") + 
  labs(
    title = "Total vs. Average Bananas Consumed per Time Period",
    x = "Time Period",
    y = "Value"
  ) +
  theme_dark() +
  theme(
    panel.grid.major = element_line(color = "lightgrey", size = 0.5),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(fill = "lightblue", color = "darkblue"),
    strip.text = element_text(color = "white", face = "bold"),
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.title.x = element_text(face = "bold", size = 12),
    axis.title.y = element_text(face = "bold", size = 12, color = "#008080"),
    axis.text.y = element_text(color = "black"),
    panel.background = element_rect(fill = "transparent", color = NA),
    plot.background = element_rect(fill = "transparent", color = NA),
    legend.background = element_rect(fill = "transparent", color = NA), 
    legend.text = element_text(color = "white", size = 12)
  )
vis_time_1 <- ggplotly(time_1)
vis_time_1
```

####ANOVA Table
```{r}
anova_results <- aov(bananas_consumed ~ time_period, data = Consumption_Log)
anova_df <- tidy(anova_results)
knitr::kable(anova_df)
```



####Tukey's post doc test to see what was different 
```{r}
tukey_results <- tidy(TukeyHSD(aov(bananas_consumed ~ time_period, data = Consumption_Log)))
tukey_plot <- ggplot(tukey_results, aes(x = contrast, y = estimate)) +
  geom_point(size = 3, color = "white") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2, color = "white") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "white") +
  coord_flip() +
  labs(
    title = "Tukey's HSD Test Results",
    x = "Comparison of time differnces ",
    y = "Mean Difference"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.background = element_rect(fill = "black", color = NA),
    plot.background = element_rect(fill = "black", color = NA),
    panel.grid.major = element_line(color = "gray"),
    panel.grid.minor = element_line(color = "darkgray"),
    axis.title = element_text(color = "white"),
    axis.text = element_text(color = "white"),
    plot.title = element_text(color = "white", hjust = 0.5)
  )

vistime_2 <- ggplotly(tukey_plot)
vistime_2
```

### Tab 3: Stuff that did not affect the relatiobship between CONSUMPTION

#### Ripeness optimization

```{r}
Consumption_Log$ripeness <- as.factor(Consumption_Log$ripeness)

ripeness_labels <- c(
  `1` = "Ripeness Level 1: Least Ripe",
  `2` = "Ripeness Level 2: Slightly Ripe",
  `3` = "Ripeness Level 3: Moderately Ripe",
  `4` = "Ripeness Level 4: Very Ripe",
  `5` = "Ripeness Level 5: Fully Ripe"
)


density_plot <- ggplot(Consumption_Log, aes(x = bananas_consumed, fill = ripeness)) +
  geom_density(alpha = 0.7, color = "blue") +
  facet_wrap(~ ripeness, scales = "free_y", labeller = as_labeller(ripeness_labels)) +
  theme_minimal() +
  labs(title = "Density of Banana Consumption by Ripeness",
       x = "Bananas Consumed",
       y = "Density") +
  scale_fill_viridis_d() +
  theme(panel.background = element_rect(fill = "transparent"),
        legend.position = "None",
        plot.background = element_rect(fill = "transparent", color = NA),
        axis.title = element_text(color = "white"),
        axis.ticks = element_line(color = "white"),
        axis.text = element_text(color = "white", size = 12, face = "bold"), 
        legend.text = element_text(color = "white", size = 14, face = "bold"), 
  
  )


density_plotly <- ggplotly(density_plot)
density_plotly
```
#### Kruskal Wallis Test results 
```{r}
kruskal_test <-  kruskal.test(bananas_consumed ~ ripeness, data = Consumption_Log)
kruskal_df <- tidy(kruskal_test)
knitr::kable(kruskal_df)
```


#### Bar graph
```{r}
Pie_chart_thrown <- bananas_thrown_away %>% 
  group_by(ripeness) %>%
  summarize(
    thrown_count = sum(thrown_away),
    total_count = n()
  ) %>%
  mutate(
    throwaway_rate = (thrown_count / total_count) * 100
  )

ripeness_labels <- c(
  `1` = "Ripeness Level 1: Least Ripe",
  `2` = "Ripeness Level 2: Slightly Ripe",
  `3` = "Ripeness Level 3: Moderately Ripe",
  `4` = "Ripeness Level 4: Very Ripe",
  `5` = "Ripeness Level 5: Fully Ripe"
)

faceted_data <-  Pie_chart_thrown %>%  
  pivot_longer(
    cols = c(thrown_count, throwaway_rate), 
    names_to = "metric", 
    values_to ="value"
  )
filtered_data <- faceted_data %>%
  filter(!(ripeness == "1" & value == 0))



bar <- ggplot(faceted_data, aes(x = "", y = value, fill = factor(ripeness))) +
  geom_bar(stat = "identity", position = "Dodge", width = 1) +
  facet_wrap(
    ~ metric, 
    scales = "free", 
    labeller = as_labeller(
      c(
        "thrown_count" = "Count of Bananas Thrown Away",
        "throwaway_rate" = "Percentage of Bananas Thrown Away"
      )
    )
  ) +
  labs(
    title = "Banana Throwaway Analysis by Ripeness",
    fill = "Ripeness Level", 
    x = "Ripeness level"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title = element_text(
      size = 15,       
      face = "bold",   
      hjust = .5, 
    )
  )

bar_plot <- ggplotly(bar)

bar_plot

```

#### Pie chart
```{r}
 ggplot(faceted_data, aes(x = "", y = value, fill = factor(ripeness))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") +
  facet_wrap(
    ~ metric, 
    labeller = as_labeller(
      c(
        "thrown_count" = "Count of Bananas Thrown Away",
        "throwaway_rate" = "Percentage of Bananas Thrown Away"
      )
    )
  ) +
  labs(
    title = "Banana Throwaway Analysis by Ripeness",
    fill = "Ripeness Level"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title = element_text(
      size = 15,
      face = "bold",
      hjust = 0.5
    )
  )



```


### Tab 4: The dreaded ML part {#ML_part}

